de facto standard for most big data storage and processing
	java based framework for distro and processing large data sets across clusters
important components
	HDFS: low level sistributed file processing system that can be used directly for data storage
	 mapreduce: programming model that supports processing large data sets
once you write data for hadoop it is immutable